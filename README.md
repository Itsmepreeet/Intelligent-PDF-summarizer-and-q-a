PDF Q&A and Summarization with LangGraph

An AI-powered interactive PDF assistant built with LangChain, LangGraph, FAISS, HuggingFace Embeddings, and Streamlit.

This tool allows you to:

ğŸ“‚ Upload any PDF document

â“ Ask natural language questions about the content

ğŸ“ Generate concise, context-aware answers with page references

ğŸ“‘ Summarize entire PDFs (hierarchical chunk-based summarization)

ğŸ”„ Automatically rephrase/refine unclear queries for better retrieval

âœ… Grade retrieved documents to ensure only relevant results are used

ğŸš€ Features
ğŸ”¹ PDF Processing

Loads PDFs using PyPDFLoader (fallback: UnstructuredPDFLoader)

Cleans and normalizes text for better chunking

Splits into overlapping chunks (RecursiveCharacterTextSplitter)

ğŸ”¹ Embeddings & Vector Store

Uses HuggingFace nomic-embed-text-v1 embeddings

Stores chunks in a FAISS vector store

Provides similarity & MMR-based retrieval

ğŸ”¹ Intelligent RAG Workflow (LangGraph)

Retriever â†’ Finds relevant chunks from the PDF

Retriever Grader â†’ Filters irrelevant results with an LLM-based relevance check

Question Rewriter â†’ Converts conversational queries into standalone questions

Refine Question â†’ Iteratively improves queries if retrieval fails

Summarizer â†’ Multi-step chunk summarization + hierarchical merging for large PDFs

Generate Answer â†’ Produces clear, concise responses with references

Cannot Answer â†’ Gracefully handles unanswered queries

ğŸ”¹ User Interface (Streamlit)

Intuitive chat-like interface (st.chat_input)

Displays both answers and referenced page numbers

PDF Upload + Question/Answer in real-time

ğŸ› ï¸ Tech Stack

LangChain â€“ Orchestrates LLM pipelines

LangGraph â€“ State-based reasoning workflow

FAISS â€“ Vector similarity search

HuggingFace Embeddings â€“ Dense vector embeddings

Groq Llama 3.1 â€“ Fast inference LLM for Q&A & summarization

Streamlit â€“ Interactive UI for chatting with PDFs

Python 3.10+

ğŸ“‚ Project Structure
ğŸ“¦ pdf-qa-langgraph
â”œâ”€â”€ app.py                # Main Streamlit app (the code you provided)
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ faiss_index/           # FAISS vector index storage
â”œâ”€â”€ .env                   # API keys / environment variables
â””â”€â”€ README.md              # Documentation

âš™ï¸ Installation
1ï¸âƒ£ Clone the Repository
git clone https://github.com/<your-username>/pdf-qa-langgraph.git
cd pdf-qa-langgraph

2ï¸âƒ£ Create Virtual Environment
python -m venv venv
source venv/bin/activate   # Linux / Mac
venv\Scripts\activate      # Windows

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Set Environment Variables

Create a .env file:

GROQ_API_KEY=your_groq_api_key_here

5ï¸âƒ£ Run the App
streamlit run app.py

ğŸ’¡ Usage

Upload a PDF document

Type your question in the chat box

Example: â€œSummarize the PDF in 5 bullet pointsâ€

Example: â€œWhat does section 2.3 talk about?â€

Get concise answers with page references

ğŸ§  Workflow Explanation
flowchart TD
    A[User Question] --> B[Task Router]
    B -->|If Summarization| C[Summarize PDF]
    B -->|Else| D[Question Rewriter]
    D --> E[Retriever]
    E --> F[Retrieval Grader]
    F -->|Relevant Docs| G[Generate Answer]
    F -->|No Docs & Retries < 2| H[Refine Question]
    F -->|No Docs & Retries â‰¥ 2| I[Cannot Answer]
    H --> E
    C --> B
    G --> J[Final Answer with Page References]
    I --> J

ğŸ”® Future Improvements

 Support for multiple file uploads

 Multi-modal retrieval (PDF + images)

 Persistent FAISS storage across sessions

 Fine-grained summarization (per section/chapter)

 Export chat history & summaries as PDF

ğŸ¤ Contributing

Contributions are welcome! Please fork this repo, make changes, and submit a pull request.

